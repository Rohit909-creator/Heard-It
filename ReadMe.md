# ğŸ”Š Heard-it: Advanced Wakeword & Phrase Detection

**Heard-it** is an advanced audio-based wakeword and phrase detection engine designed to not just detect specific hotwords, but also understand **commands** and **phrases**. Built with deep learning at its core, this framework is designed for real-time, on-device audio inference and training.

> ğŸš§ *This project is a work in progress â€“ with exciting features in development, including customizable classification from rich audio embeddings. Although there are trial versions of this available here*

---

## ğŸ“¦ Project Structure

```
â”œâ”€â”€ main.py              # Live Wakeword Detection using current model
â”œâ”€â”€ Augmentation.py      # Audio data augmentation pipeline
â”œâ”€â”€ Trainer.py           # Model definitions, training loop, and dataloaders
â”œâ”€â”€ Preprocessing.py     # Audio preprocessing and feature extraction
â”œâ”€â”€ Inference.py         # Inference pipeline using trained models
â”œâ”€â”€ Audio_dir/           # Directory containing training audio (linked via GDrive)
â”œâ”€â”€ lightning_logs/      # Trained model checkpoints (linked via GDrive)
```

---

## ğŸ§  Model Architectures

Weâ€™re currently experimenting with the following architectures:

- âœ… **ResNet-18** â€“ Best performing so far in terms of accuracy and generalization.
- ğŸ§ª **CRNN (CNN + RNN)** â€“ Tested, but hasnâ€™t shown promising results yet.
- ğŸ”œ **(Planned)** Transformer-based audio models or wav2vec-inspired encoders.

Our goal is to create **rich embeddings** that allow for **custom wakeword** and **phrase classification** from user-supplied audio.

---

## ğŸ› ï¸ Features

- ğŸ™ï¸ Live audio stream detection (`main.py`)
- ğŸ“ˆ Model training and evaluation with Pytorch Lightning
- ğŸ§ Preprocessing pipeline using Mel Spectrograms
- ğŸ” Data Augmentation support for robust training
- ğŸ“‚ Google Drive links for datasets and model weights (see below)
- ğŸ” Inference module for running predictions on saved checkpoints

---

## ğŸ”— External Assets

- ğŸµ **Audio Dataset (Audio_dir/)**: [Audio_dir](https://drive.google.com/file/d/1nt7fNs_OKq5X4Tk-IXCx8ueU8_-Q-f3I/view?usp=sharing)
- ğŸ§  **Pretrained Models (lightning_logs/)**: [lightning_logs](https://drive.google.com/drive/folders/1K9Hm2QLoNGrEdXQscS4_aeEHWDdV6Rsd?usp=sharing)
- ğŸ¤ğŸ§  **Pretrained Models (Mini Model 21Mb/)**: [lightning_logs](https://drive.google.com/drive/folders/1K9Hm2QLoNGrEdXQscS4_aeEHWDdV6Rsd?usp=sharing)

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/Rohit909-creator/Heard-It
cd Heard-It/src/
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Run Live Detection

```bash
python main.py
```

### 4. Train a Model

```bash
python Trainer.py
```

### 5. Run Inference

```bash
python Inference2.py
```

---

## ğŸ§ª Sample Use-Case

Detect wakewords like:
- `"Jarvis"`
- `"Heard-it"`
- `"Alexa"`
- Or any **custom phrase** of your choice by using your audio of saying that wakeword as reference!

---

## ğŸ’¡ Goals & Roadmap

- [x] Real-time Wakeword Detection
- [x] Data Augmentation Pipeline
- [x] Training with ResNet18
- [x] Custom Wakeword Support from User Input
- [ ] Custom Phrase detection Support from User Input
- [ ] Model Quantization for Mobile
- [ ] Android/iOS Compatibility (TFLite/ONNX export)
- [ ] Rich Embedding Visualizer

---

## ğŸ‘¨â€ğŸ’» Contributors

- **Me** â€“ [@Rohit Francis](https://github.com/Rohit909-creator)